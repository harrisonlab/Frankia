# Frankia README 

# Acquiring all Frankia genomes from NCBI 

wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/058/485/GCA_000058485.1_ASM5848v1/GCA_000058485.1_ASM5848v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/177/615/GCA_000177615.2_ASM17761v2/GCA_000177615.2_ASM17761v2_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/018/005/GCA_000018005.1_ASM1800v1/GCA_000018005.1_ASM1800v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/013/345/GCA_000013345.1_ASM1334v1/GCA_000013345.1_ASM1334v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/374/165/GCA_000374165.1_ASM37416v1/GCA_000374165.1_ASM37416v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/166/135/GCA_000166135.1_ASM16613v1/GCA_000166135.1_ASM16613v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/017/755/GCA_001017755.1_ASM101775v1/GCA_001017755.1_ASM101775v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/373/365/GCA_000373365.1_ASM37336v1/GCA_000373365.1_ASM37336v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/900/067/225/GCA_900067225.1_Dg2/GCA_900067225.1_Dg2_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/983/105/GCA_001983105.1_ASM198310v1/GCA_001983105.1_ASM198310v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/235/425/GCA_000235425.3_ASM23542v3/GCA_000235425.3_ASM23542v3_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/536/285/GCA_001536285.1_IMG-taxon_2634166352_annotated_assembly/GCA_001536285.1_IMG-taxon_2634166352_annotated_assembly_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/900/197/875/GCA_900197875.1_FRACA_ARgP5/GCA_900197875.1_FRACA_ARgP5_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/948/395/GCA_000948395.1_CpI1-S/GCA_000948395.1_CpI1-S_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/900/241/035/GCA_900241035.1_Frankia_canadensis/GCA_900241035.1_Frankia_canadensis_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/636/575/GCA_001636575.1_ASM163657v1/GCA_001636575.1_ASM163657v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/262/465/GCA_000262465.1_ASM26246v1/GCA_000262465.1_ASM26246v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/966/285/GCA_000966285.1_ASM96628v1/GCA_000966285.1_ASM96628v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/002/099/355/GCA_002099355.1_ASM209935v1/GCA_002099355.1_ASM209935v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/611/815/GCA_000611815.2_ASM61181v2/GCA_000611815.2_ASM61181v2_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/177/675/GCA_000177675.1_ASM17767v1/GCA_000177675.1_ASM17767v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/421/445/GCA_000421445.1_ASM42144v1/GCA_000421445.1_ASM42144v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/306/465/GCA_001306465.1_ASM130646v1/GCA_001306465.1_ASM130646v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/636/565/GCA_001636565.1_ASM163656v1/GCA_001636565.1_ASM163656v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/756/285/GCA_001756285.1_ASM175628v1/GCA_001756285.1_ASM175628v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/854/645/GCA_001854645.1_ASM185464v1/GCA_001854645.1_ASM185464v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/854/655/GCA_001854655.1_ASM185465v1/GCA_001854655.1_ASM185465v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/854/695/GCA_001854695.1_ASM185469v1/GCA_001854695.1_ASM185469v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/854/725/GCA_001854725.1_ASM185472v1/GCA_001854725.1_ASM185472v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/854/805/GCA_001854805.1_ASM185480v1/GCA_001854805.1_ASM185480v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/983/005/GCA_001983005.1_ASM198300v1/GCA_001983005.1_ASM198300v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/983/015/GCA_001983015.1_ASM198301v1/GCA_001983015.1_ASM198301v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/983/215/GCA_001983215.1_ASM198321v1/GCA_001983215.1_ASM198321v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/002/099/325/GCA_002099325.1_ASM209932v1/GCA_002099325.1_ASM209932v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/900/465/275/GCA_900465275.1_Frankia_Ea1-12/GCA_900465275.1_Frankia_Ea1-12_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/503/735/GCA_000503735.2_CcI6/GCA_000503735.2_CcI6_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/685/765/GCA_000685765.2_BMG5.23v1/GCA_000685765.2_BMG5.23v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/732/115/GCA_000732115.1_CeD/GCA_000732115.1_CeD_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/733/325/GCA_000733325.1_ASM73332v1/GCA_000733325.1_ASM73332v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/414/035/GCA_001414035.1_ACN1AG/GCA_001414035.1_ACN1AG_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/420/875/GCA_001420875.1_Avc1/GCA_001420875.1_Avc1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/421/075/GCA_001421075.1_ASM142107v1/GCA_001421075.1_ASM142107v1_genomic.fna.gz


# Make PROKKA database using the Frankia genbank files 

prokka-genbank_to_fasta_db *gbff > frankia.faa
cd-hit -i frankia.faa -o frankia -T 0 -M 0 -g 1 -s 0.8 -c 0.9
rm -fv frankia.faa frankia.bak.clstr frankia.clstr
makeblastdb -dbtype prot -in frankia
mv frankia.p* /home/hulinm/local/src/prokka/db/genus/

# Run PROKKA annotation and then gzip fasta files
for file in /home/hulinm/frankia/genomes/*.fa ; do 
file_short=$(basename $file | sed s/".fa"//g) 
prokka  --usegenus --genus frankia $file --outdir $file_short
gzip $file 
done 

## Filtering of genomes based on bacteial GWAS paper (Levy et al. 2018)
# Only keep those with N50 >=40000bp. 
# First run quast.py on all genomes to get report


python /home/hulinm/git_repos/tools/analysis/python_effector_scripts/extract_N50filtered_genomes.py transposed_report.tsv > report2.txt 
cut -f1 -d " " report2.txt | uniq > report3.txt
for file in $(cat /home/hulinm/frankia/genomes/quast_results/results_2018_11_03_14_51_36/report3.txt) ; do 
cp "$file".fa ./filtered/
done

# CheckM contamination screen to remove those genomes that have >5% contamination level

for file in ./*.fa ; do
    file_short=$(basename $file | sed s/".fa"//g)
    echo $file_short
    mkdir -p ./checkm/"$file_short"
    cp $file ./checkm/"$file_short"
    Jobs=$(qstat | grep 'checkm' | wc -l)
    while [ $Jobs -gt 7 ]
    do
        sleep 10
        printf "."
        Jobs=$(qstat | grep 'checkm' | wc -l)
    done
    qsub /home/hulinm/git_repos/pseudomonas/sub_checkm.sh /home/hulinm/frankia/genomes/filtered/checkm/"$file_short" /home/hulinm/frankia/genomes/filtered/checkm/"$file_short"/checkm
done


for file in ./*fa ; do 
    file_short=$(basename $file | sed s/".fa"//g)
    
 checkm qa /home/hulinm/frankia/genomes/filtered/checkm/"$file_short"/checkm/lineage.ms /home/hulinm/frankia/genomes/filtered/checkm/"$file_short"/checkm > /home/hulinm/frankia/genomes/filtered/checkm/"$file_short"/checkm/report

done



# OrthoFinder for orthology analysis

# Rename ffn file to contain genome name not PROKKA output 
for file in /home/hulinm/frankia/genomes/*.fa ; do 
file_short=$(basename $file | sed s/".fa"//g) 
echo $file_short
cp /home/hulinm/frankia/annotation/"$file_short"/*.faa /home/hulinm/frankia/annotation/"$file_short"/"$file_short".faa 


# Move all faa files to orthomcl directory within /home/hulinm/frankia/analysis/orthofinder/formatted

cp /home/hulinm/frankia/annotation/*/*.faa .

# Modify all fasta files to remove description and get into correct format for OrthMCL
# Each fasta item must be in format of strain|peg.number

for file in /home/hulinm/frankia/analysis/*.faa ; do  
file_short=$(basename $file | sed s/".faa"//g | cut -f1 -d ".") 
echo $file_short
sed -e 's/^\(>[^[:space:]]*\).*/\1/' $file | sed s/"_"/"|peg."/g  > "$file_short".fa
done

for file in /home/hulinm/frankia/analysis/*.fa ; do 
id=$(less $file | grep ">" | cut -f1 -d "|" | sed s/">"//g | uniq) 
file_short=$(basename $file | sed s/".fa"//g) 
echo $id 
echo $file_short
sed s/"$id"/"$file_short"/g $file > $file_short.fasta

# Remove manually those that did not pass CheckM and also those that did not pass N50 limit 

for file in /home/hulinm/frankia/genomes/filtered/*.fa ; do 
file_short=$(basename $file | sed s/".fa"//g | cut -f1,2 -d _ | cut -f1 -d .) 
echo $file_short
mv /home/hulinm/frankia/analysis/"$file_short".fasta /home/hulinm/frankia/analysis/orthofinder/formatted/"$file_short".fasta


# OrthoFinder run

/home/hulinm/local/src/OrthoFinder-2.2.7_source/orthofinder/orthofinder.py  -f formatted -t 16 -S diamond 




# Build a phylogeny using raxml from concatenated single copy protein sequences 

# fasta of all protein sequences generated by concatenating all faa files 

cat *.faa > /home/hulinm/frankia/analysis/orthofinder/formatted/proteins.fa 

# Extract fasta sequences for each orthogroup
WorkDir=/home/hulinm/frankia/analysis/orthofinder/formatted/Results_Nov14_1
sed s/"OG"/"orthogroup"/g $WorkDir/Orthogroups.txt > $WorkDir/Orthogroups.txt2
sed s/"OG"/"orthogroup"/g $WorkDir/SingleCopyOrthogroups.txt > $WorkDir/SingleCopyOrthogroups.txt2
python /home/hulinm/git_repos/tools/pathogen/orthology/orthoMCL/orthoMCLgroups2fasta.py --orthogroups $WorkDir/Orthogroups.txt2  --fasta /home/hulinm/frankia/analysis/orthofinder/formatted/proteins.fa  --out_dir $WorkDir/fasta/


WorkDir=/home/hulinm/frankia/analysis/orthofinder/formatted/Results_Nov14_1
for file in $(cat $WorkDir/SingleCopyOrthogroups.txt2) ; do 
echo $file
cp  $WorkDir/fasta/"$file".fa $WorkDir/fasta/single_copy

# Alignment of proteins sequences of each OG 
WorkDir=/home/hulinm/frankia/analysis/orthofinder/formatted/Results_Nov14_1
for fasta in $WorkDir/fasta/single_copy/*.fa  ; do
    file_short=$(basename $fasta | sed s/".fa"//g)
    Jobs=$(qstat | grep 'sub_clustal' | wc -l)
    while [ $Jobs -gt 100 ]
    do
        sleep 10
        printf "."
        Jobs=$(qstat | grep 'sub_clustal' | wc -l)
    done
qsub /home/hulinm/git_repos/pseudomonas/orthomcl/sub_clustal.sh $fasta
done

# GBLOCKS to correct alignments 

rm *dnd
rm *fa
rm sub*

WorkDir=/home/hulinm/frankia/analysis/orthofinder/formatted/Results_Nov14_1
for file in $WorkDir/fasta/single_copy/*.fasta ; do
Gblocks $file -t=p -d=y #Change -t to p or d for protein/dna
echo $file
done

# rename sequences to make them shorter and compatible with phylogenetic programs 
WorkDir=/home/hulinm/frankia/analysis/orthofinder/formatted/Results_Nov14_1

for fasta in $WorkDir/fasta/single_copy/*-gb  ; do
name=$(basename $fasta | sed s/".fasta-gb"//g)
sed 's/peg\.[0-9]*//g' $fasta | sed s/GCA_//g   > ./align/"$name"
done

# Convert to nexus format from fasta
WorkDir=/home/hulinm/frankia/analysis/orthofinder/formatted/Results_Nov14_1

for file in $(cat $WorkDir/SingleCopyOrthogroups.txt2) ; do 
echo $file
perl /home/hulinm/git_repos/tools/analysis/python_effector_scripts/alignment_convert.pl -i $WorkDir/fasta/single_copy/align/"$file" -o $WorkDir/fasta/single_copy/align/"$file".nxs -f nexus -g fasta
done

# Concatenate single copy orthogroup alignments, remember to modify the script with correct path

python /home/hulinm/git_repos/tools/analysis/python_effector_scripts/concatenate.py

# Manually change datatype to protein using nano
# Then convert to phylip format

perl /home/hulinm/git_repos/tools/analysis/python_effector_scripts/alignment_convert.pl -i combined.nex -o combined.phy -f phylip -g nexus

# Make partition model file 
grep charset combined.nex | sed s/charset//g | sed s/".nxs"//g | sed s/"-gb"//g | sed s/" o"/"o"/g | sed s/";"//g > positions

# Get list of genes in order 
cut -f1 -d " " positions > list 


# Run the protein model tester on each individual alignment 
WorkDir=/home/hulinm/frankia/analysis/orthofinder/formatted/Results_Nov14_1
for file in $(cat $WorkDir/SingleCopyOrthogroups.txt2) ; do 
echo $file
perl /home/hulinm/git_repos/tools/analysis/python_effector_scripts/alignment_convert.pl -i $WorkDir/fasta/single_copy/align/"$file" -o $WorkDir/fasta/single_copy/align/"$file".phy -f phylip -g fasta



# Test protein models for each OG
WorkDir=/home/hulinm/frankia/analysis/orthofinder/formatted/Results_Nov14_1
for file in $WorkDir/fasta/single_copy/align/*.phy ; do
    file_short=$(basename $file | sed s/".phy"//g )
    echo $file_short
        Jobs=$(qstat | grep 'sub_protte' | wc -l)
    while [ $Jobs -gt 50 ]
    do
        sleep 10
        printf "."
        Jobs=$(qstat | grep 'sub_protte' | wc -l)
    done
    qsub /home/hulinm/git_repos/pseudomonas/sub_prottest.sh "$file" $WorkDir/fasta/single_copy/align/"$file_short"_model
done


# Get best model name into its own file 
WorkDir=/home/hulinm/frankia/analysis/orthofinder/formatted/Results_Nov14_1

for file in $WorkDir/fasta/single_copy/align/*_model 
do
    file_short=$(basename $file | sed s/"_model"//g)
	grep "Best model according to LnL" $file | cut -d " " -f6  >  $WorkDir/fasta/single_copy/align/model_"$file_short"
done

#Edit 
WorkDir=/home/hulinm/frankia/analysis/orthofinder/formatted/Results_Nov14_1
for file in $WorkDir/fasta/single_copy/align/model_* ; do 
file_short=$(basename $file | sed s/"model_"//g)
mv $file $WorkDir/fasta/single_copy/align/model/"$file_short"
done

# Remove model files
rm *_model 


# Proteins
WorkDir=/home/hulinm/frankia/analysis/orthofinder/formatted/Results_Nov14_1
for file in $(cat $WorkDir/fasta/single_copy/align/list) ; do
cat $WorkDir/fasta/single_copy/align/model/"$file" >> $WorkDir/fasta/single_copy/align/model/models
done

# Add in sequence evolution model 

# Make the final partition file 
WorkDir=/home/hulinm/frankia/analysis/orthofinder/formatted/Results_Nov14_1

mkfifo pipe1
mkfifo pipe2
cut -f1 $WorkDir/fasta/single_copy/align/model/models > pipe1 & # In order to add effector names in first column
cut -f1,2,3 $WorkDir/fasta/single_copy/align/positions > pipe2 &
paste pipe1 pipe2  > $WorkDir/fasta/single_copy/align/partition
rm pipe1 pipe2

sed s/"\t"/", "/g partition > partition_file

# Run RAxML on this concatenated protein alignment 

qsub /home/hulinm/git_repos/pseudomonas/orthomcl/sub_raxml_partition_aa.sh combined.phy output partition_file


# blasting nod genes 

for GENOME in /home/hulinm/frankia/genomes/*.fna ; do
 GENOME_FILE=$(basename $GENOME)
 GENOME_SHORT=$(echo $GENOME_FILE | sed s/.fna//g)
 echo $GENOME_SHORT
 python /home/hulinm/git_repos/tools/analysis/python_effector_scripts/rename.py -i "$GENOME_SHORT".fna -o "$GENOME_SHORT".fa
 gzip "$GENOME_SHORT".fna



for genome in /home/hulinm/frankia/genomes/*.fa ; do
  echo $genome
  file=$(basename $genome)
  genome_short=$(echo $file | sed s/.fa//g)
  echo $genome_short

  for query in /home/hulinm/frankia/nod_genes/*.fa ; do
    echo $query
    query_short=$(basename $query | sed s/.fa//g)

/home/hulinm/git_repos/tools/pathogen/blast/blast2csv.pl $query tblastn   $genome   5 > /home/hulinm/frankia/nod_genes/blast/"$genome_short"_"$query_short"
done
done

